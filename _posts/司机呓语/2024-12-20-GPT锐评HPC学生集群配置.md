##### August说：

我们考虑一场国际顶级大学生超算竞赛的某队伍搭建集群场景。 假定我们有一个机架，4个柜式服务器，每个机柜可放2节点，采用2 x Intel Xeon Scalable Cascade Lake 6248(2.5GHz, 20 cores) NUMA Mem:12 x Samsung 16GB DDR4 ECC REG 2666。共要用8张NVIDEA P100，且各计算节点全连接到一个外接公网的100Gbps以太网交换机+一台IB交换机。 要求集群瞬时总功率不得超过3kW。 比赛临时用，故无需登陆节点、无需可视化接口、暂时无需调度系统。 请分析： 1. 这个物理机集群架构如何配置？ 2. 如果GPU要全用，cpu最多同时开几个节点？ 3. 详细说明网络设备需要配置多少端口、对光纤和IB线的需求。 4. Mellanox EDR 和 FDR配置理论上会造成多少性能差异？omnipath又会带来哪些影响？ 5. 该集群暂时用计算节点配置高速SSD作为本地存储，未来如何挂载LUSTRE文件系统扩展？如何挂载scratch闪存并行辅文件系统？



###### ChatGPT 说：

ChatGPT

### **问题分析及解决方案**

#### **1. 物理机集群架构配置**

- **服务器配置**
  - 每台服务器包含2个节点，每节点配置：
    - 2 x Intel Xeon Scalable Cascade Lake 6248 (2.5GHz, 20 cores)
    - 12 x Samsung 16GB DDR4 ECC REG 2666 (总内存384GB)
    - 1 x NVIDIA P100 GPU（每个节点配备1张）
    - 一个PCIe插槽用于高速网络连接（如IB或100Gbps Ethernet）
  - 4台服务器，总计8节点。
- **功率限制**
  - 服务器总功耗：
    - CPU: 每颗6248约150W，2颗 = 300W
    - 内存：每条16GB DDR4功耗约4W，12条 = 48W
    - GPU: 每张NVIDIA P100约250W，1张 = 250W
    - 其余主板、风扇等约50W。
    - 单节点功耗总计：650W
    - 单服务器（2节点）：1300W，4台服务器总计5200W。
    - **显然超出3kW限制，需要部分CPU核心关闭（见问题2）来降低功耗。**
- **网络设备**
  - 1台100Gbps Ethernet交换机：连接外部公网和节点。
  - 1台Infiniband交换机：用于节点间高性能通信（使用Mellanox FDR或EDR）。

#### **2. CPU最多同时开几个节点**

为满足3kW限制，集群总功率需≤3000W。根据估算：

- 若每节点功耗减半（325W），集群总功耗：325×8=2600 W325 \times 8 = 2600 \, \text{W}325×8=2600W。
- 降低功耗的措施：
  - 关闭部分CPU核心：
    - 每颗6248有20核，关闭一半（10核）预计降低功耗至约75W。
    - 节点功耗变为325W（原650W减半），满足3kW限制。
- 结论：**通过关闭部分CPU核心，8节点可同时运行。**

#### **3. 网络设备配置及需求**

**交换机及端口需求**：

- **100Gbps以太网交换机**：
  - 8个计算节点 + 1个外接公网连接 = 至少9个100Gbps端口。
  - 光纤需求：100Gbps光模块及光纤，至少9根。
- **IB交换机（如Mellanox）**：
  - 用于计算节点间高速通信。
  - 每节点1个端口，共需8个端口。
  - IB线缆需求：8根（节点到交换机）。

**光纤与IB线材**：

- 光纤长度根据机房布局决定（一般短距建议用OM4多模光纤）。
- IB线缆通常采用Mellanox DAC（Direct Attach Copper）或AOC（Active Optical Cable）。

#### **4. Mellanox EDR 和 FDR的性能差异及Omnipath的影响**

- **EDR与FDR性能差异**：

  - 数据速率

：

    - FDR（Fourteen Data Rate）：56Gbps。
    - EDR（Enhanced Data Rate）：100Gbps。

  - 性能差异

：

    - 数据传输速率提升约78%（理论值）。
    - 对实际应用性能的影响：
      - 带宽敏感型应用（如大规模矩阵运算）：EDR表现显著优于FDR。
      - 延迟差异较小（FDR 700ns vs. EDR 600ns）。
    - **结论**：EDR更适合需要更高带宽的计算任务。

- **Omnipath的影响**：

  - Intel Omnipath具有较低的延迟（约300ns），带宽高达100Gbps，与Mellanox EDR接近。
  - Omnipath优点：更高的性价比，适合预算较低场景。
  - 缺点：社区支持和硬件生态不如Mellanox。

#### **5. LUSTRE文件系统和闪存文件系统扩展**

- **LUSTRE文件系统扩展**：
  - 配置：
    - OSS（Object Storage Server）：提供并行I/O存储。
    - MDS（Metadata Server）：负责元数据管理。
  - 方案：
    - 将Lustre OSS和MDS节点单独部署在一台服务器。
    - 使用高速网络（IB或100Gbps Ethernet）挂载到计算节点。
    - 配置共享存储（如RAID阵列）作为存储后端。
- **Scratch闪存并行文件系统**：
  - 在各计算节点上安装高速SSD作为本地临时存储。
  - 利用并行文件系统软件（如BeeGFS或Alluxio）协调节点间数据共享。
  - 未来优化方向：
    - 引入NVMe SSD以提升I/O性能。
    - 在SSD与Lustre间设置智能数据缓存层。

希望这些回答能帮你完成超算竞赛场景的架构分析！





##### August说：

你的回答很好。我们假定实际比赛中采用只保留4个物理cpu并配置8张GPU的方案，分析满功率运行的最坏情况下否会超出功率？在赛场要求1个白天内从零开始组建该系统，需要如何组织多少大学生完成合适？



###### ChatGPT 说：

ChatGPT

### **分析最坏情况下是否超出功率限制**

假定只保留4个物理CPU，并配置8张NVIDIA P100 GPU，满功率运行时的功耗估算如下：

#### **1. 单节点功耗估算**

- **CPU功耗**：
  - 每颗Intel Xeon 6248满功耗约150W。
  - 保留4颗CPU，总功耗为 4×150=600 W4 \times 150 = 600 \, \text{W}4×150=600W。
- **GPU功耗**：
  - 每张NVIDIA P100满功耗约250W。
  - 总功耗为 8×250=2000 W8 \times 250 = 2000 \, \text{W}8×250=2000W。
- **内存功耗**：
  - 每条16GB DDR4约4W，12条每节点总功耗48W。
  - 总功耗为 48×4=192 W48 \times 4 = 192 \, \text{W}48×4=192W。
- **主板与其余配件功耗**：
  - 主板、风扇、存储设备约50W每节点。
  - 总功耗为 50×4=200 W50 \times 4 = 200 \, \text{W}50×4=200W。

#### **2. 总功耗估算**

总功耗=CPU功耗+GPU功耗+内存功耗+其他配件功耗\text{总功耗} = \text{CPU功耗} + \text{GPU功耗} + \text{内存功耗} + \text{其他配件功耗}总功耗=CPU功耗+GPU功耗+内存功耗+其他配件功耗总功耗=600+2000+192+200=2792 W\text{总功耗} = 600 + 2000 + 192 + 200 = 2792 \, \text{W}总功耗=600+2000+192+200=2792W

- 结果：

  - 满功率运行时，总功耗 2792 W2792 \, \text{W}2792W 小于 3000W，不会超出功率限制。

------

### **组织赛场搭建系统的人员需求分析**

#### **1. 工作任务划分**

从零开始组建该系统需完成以下步骤：

1. 机架硬件安装：

   - 服务器、GPU、交换机安装、布线及电源连接。

2. 操作系统和驱动安装：

   - 安装Linux（如RHEL或Ubuntu）及配置必要驱动（如GPU驱动、IB驱动）。

3. 网络配置：

   - 设置IP地址，配置100Gbps以太网和IB通信。

4. 软件环境搭建：

   - 安装计算所需的库、框架（如CUDA、MPI等）。

5. 性能验证和调试：

   - 使用测试任务验证硬件和网络性能。

6. 系统优化：

   - 调整BIOS设置、关闭非必要服务以提高性能。

#### **2. 人员分工与数量**

根据任务划分，每名学生的任务及需求如下：

| 角色           | 任务描述                                         | 建议人数 |
| -------------- | ------------------------------------------------ | -------- |
| **硬件工程师** | 负责机架安装、布线、电源接入和硬件检查。         | 2人      |
| **系统管理员** | 安装操作系统、驱动及配置硬件。                   | 2人      |
| **网络管理员** | 配置网络设备，设置IP地址和交换机参数。           | 1人      |
| **软件工程师** | 搭建软件环境（CUDA、MPI等），部署测试程序。      | 2人      |
| **性能调优师** | 运行测试任务，调试性能，解决硬件或网络性能瓶颈。 | 1人      |
| **总协调人**   | 监督进度，分配任务，协调问题解决。               | 1人      |

#### **3. 时间预算**

- 硬件安装：4小时。
- 操作系统和驱动安装：2小时。
- 网络配置：1小时。
- 软件环境搭建：3小时。
- 性能验证和优化：2小时。
- 总计：约12小时。

#### **4. 总结**

- 需要至少 **9名大学生** 分工合作，熟练掌握相关技能（硬件安装、Linux系统配置、网络调试等）。
- 如果参与者经验丰富，工作时间可以进一步压缩。

------

**建议**：

1. 提前准备硬件设备和必要的驱动程序。
2. 制定明确分工和任务时间表，避免人员重复工作。
3. 在模拟环境中进行1-2次演练，确保现场搭建顺利完成。



##### August说：

大致准确，但有些需要微调。OS我们采用Centos 7. 性能验证要调整参数做多轮HPL+HPCG以取得最优性能。请完善



###### ChatGPT 说：

ChatGPT

### **完善后的方案分析**

在实际比赛中，考虑采用 **CentOS 7** 作为操作系统，并通过多轮 **HPL** 和 **HPCG** 测试验证和调整性能，以下是更加具体的方案调整和完善。

------

### **1. 总功耗分析：维持不超过3kW**

#### 硬件功耗评估：

1. **CPU功耗**：
   - 使用4颗Intel Xeon 6248，满载功耗约 4×150=600 W4 \times 150 = 600 \, \text{W}4×150=600W。
2. **GPU功耗**：
   - 8张NVIDIA P100 GPU满功耗为 8×250=2000 W8 \times 250 = 2000 \, \text{W}8×250=2000W。
3. **内存功耗**：
   - 每条16GB DDR4约4W，4节点共48条，功耗 48×4=192 W48 \times 4 = 192 \, \text{W}48×4=192W。
4. **其他组件功耗**：
   - 主板、风扇和存储设备合计约200W。

#### **总功耗**：

总功耗=600+2000+192+200=2792 W (<3000 W)\text{总功耗} = 600 + 2000 + 192 + 200 = 2792 \, \text{W} \, (< 3000 \, \text{W})总功耗=600+2000+192+200=2792W(<3000W)

**结论**：功耗在限制范围内，无需额外措施。

------

### **2. 性能验证方案：HPL 和 HPCG**

比赛要求运行多轮 **HPL（High-Performance Linpack）** 和 **HPCG（High Performance Conjugate Gradient）**，以取得最优性能。具体步骤：

#### **HPL测试流程**

1. **准备HPL环境**：

   - 确保安装 `Intel MKL` 或 `OpenBLAS` 提供的高性能线性代数库。
   - 下载和配置 HPL 测试程序。

2. **HPL参数调整**：

   - 配置文件 

     ```
     HPL.dat
     ```

      中需优化以下参数：

     - NNN：矩阵大小，选取能充分利用内存的值。
     - NBNBNB：分块大小，通常为32到512之间。
     - P,QP, QP,Q：进程网格布局，确保 P×Q=总核数P \times Q = \text{总核数}P×Q=总核数。

   - 通过多轮实验逐步优化 NB,P,QNB, P, QNB,P,Q 参数。

3. **测试运行**：

   - 运行HPL，记录性能（GFLOPS），逐步调整参数，寻找最优解。

#### **HPCG测试流程**

1. **准备HPCG环境**：
   - 确保安装HPCG工具（官方提供编译好的版本）。
   - 配置运行环境。
2. **HPCG参数优化**：
   - 调整问题大小（Problem Size），确保GPU和内存资源充分利用。
   - 配置MPI和OpenMP线程的分配。
3. **测试运行**：
   - 运行HPCG测试，记录性能（GFLOPS）。
   - 调整线程绑定和GPU分配策略，观察性能变化。

#### **多轮测试目标**

- 多轮运行HPL和HPCG，逐步优化参数。
- 确保最终性能接近设备理论峰值（HPL效率通常达80-90%，HPCG较低）。

------

### **3. 系统搭建流程优化（针对CentOS 7）**

#### **安装与配置步骤**

1. **硬件安装（4小时）**：

   - 安装4台服务器到机架并连接电源。
   - 插入8张NVIDIA P100 GPU，确认PCIe连接无误。
   - 配置100Gbps Ethernet和IB交换机，连接节点。

2. **CentOS 7安装与基本配置（2小时）**：

   - 从USB或网络安装CentOS 7，并配置最小化安装。

   - 安装必要的依赖包：

     ```bash
     yum groupinstall "Development Tools"
     yum install epel-release kernel-devel -y
     ```

3. **GPU驱动与CUDA安装（1小时）**：

   - 安装NVIDIA官方驱动和CUDA工具包：

     ```bash
     yum install -y cuda
     nvidia-smi
     ```

4. **IB驱动与网络配置（1小时）**：

   - 配置Mellanox驱动，启用IB网络：

     ```bash
     yum install -y mlnx-ofed-all
     /etc/init.d/openibd start
     ```

5. **软件环境部署（2小时）**：

   - 安装MPI（如Intel MPI或OpenMPI）：

     ```bash
     yum install -y openmpi
     ```
     
   - 部署HPL和HPCG所需库（MKL或OpenBLAS）。
   
6. **多轮性能验证与调优（2小时）**：

   - 运行HPL和HPCG，调整参数，优化性能。

------

### **4. 完善人员组织及分工**

调整任务和人员安排，考虑CentOS 7及性能验证任务的特殊需求：

| 角色           | 任务描述                                                 | 建议人数 |
| -------------- | -------------------------------------------------------- | -------- |
| **硬件工程师** | 安装服务器、交换机、GPU及布线，检查硬件状态。            | 2人      |
| **系统管理员** | 安装CentOS 7，配置基本环境，部署驱动和CUDA工具。         | 2人      |
| **网络管理员** | 配置100Gbps Ethernet和IB交换机，测试网络连接性能。       | 1人      |
| **软件工程师** | 安装MPI、HPL、HPCG及相关依赖库，完成初步配置。           | 2人      |
| **性能调优师** | 调整HPL和HPCG参数，运行多轮测试以优化性能。              | 1人      |
| **总协调人**   | 分配任务，监督进度，解决突发问题，确保按时完成系统部署。 | 1人      |

#### **时间预算**

1. 硬件安装与检查：4小时。
2. 操作系统与驱动安装：3小时。
3. 网络与软件配置：3小时。
4. 性能验证与优化：2小时。
5. 总计：**约12小时**。

------

### **总结**

- **满功耗分析**：调整后总功耗 2792 W2792 \, \text{W}2792W，满足3kW限制。
- **系统部署**：通过任务分工，组织9名大学生在赛场内1个白天完成从零搭建。
- **性能验证**：通过多轮HPL和HPCG测试，逐步调整参数，最终实现性能最优。





##### August说：

好的。现在我们来分析另一场比赛。这场比赛发生在疫情期间，因此完全在Azure云上举行，可以在较大范围内选择机型，但总预算是3k美元。 预计要有72h运行各种科学计算负载，包括CESM，gromacs，AI LLM等。 无瞬时功率限制。 考虑性价比，我们推荐AMD x64架构的CPU节点 HB120rs_v3，和若干NVIDEA gpu节点 NC64as_T4_v3，组合成异构集群。 此时，必须考虑挂载高性能网络文件系统，备选有NFS BEEGFS LUSTRE（没有IB故此处先不考虑）等。 除了HPL HPCG，这次基准测试还要做 IO500。 类似地，请给出一个集群设计和分析。



###### ChatGPT 说：

ChatGPT

### **Azure云上异构集群设计与分析**

在这次比赛场景中，预算为 **3000美元**，运行时间 **72小时**，需要运行多种科学计算负载（CESM、Gromacs、AI LLM等），同时需挂载高性能文件系统并进行多项基准测试。以下是详细设计和分析。

------

### **1. 选择云实例类型**

根据任务特点和预算限制，采用 **HB120rs_v3** 和 **NC64as_T4_v3** 的异构集群架构。

#### **计算节点类型**

1. **HB120rs_v3（CPU节点，适合高性能数值模拟）**：

   - 配置：

     - CPU: 120核 AMD EPYC 7003 (Zen 3)，时钟频率3.45 GHz。
     - RAM: 448GB DDR4。
     - 支持高速本地SSD存储。

   - 适用任务：

     - CESM、HPCG、部分大规模AI训练任务。
     - **单位成本**：约1.65美元/小时（按Azure官方定价）。

2. **NC64as_T4_v3（GPU节点，适合深度学习和分子模拟）**：

   - 配置：

     - GPU: 4 x NVIDIA T4（每张GPU具有16GB显存，FP32算力8.1 TFLOPS）。
     - CPU: 64核 AMD EPYC 7V12。
     - RAM: 448GB DDR4。
     - 支持高速本地SSD存储。

   - 适用任务：

     - Gromacs、AI大模型训练、深度学习推理。
     - **单位成本**：约3.6美元/小时。

#### **节点分配**

根据预算和任务负载特性：

- **HB120rs_v3（CPU节点）**：
  - 预算分配：72 小时×2 台×1.65 美元/小时=237.6 美元72 \, \text{小时} \times 2 \, \text{台} \times 1.65 \, \text{美元/小时} = 237.6 \, \text{美元}72小时×2台×1.65美元/小时=237.6美元。
  - **分配2台**用于数值模拟和HPC负载。
- **NC64as_T4_v3（GPU节点）**：
  - 预算分配：72 小时×4 台×3.6 美元/小时=1036.8 美元72 \, \text{小时} \times 4 \, \text{台} \times 3.6 \, \text{美元/小时} = 1036.8 \, \text{美元}72小时×4台×3.6美元/小时=1036.8美元。
  - **分配4台**用于AI训练和分子模拟。
- **存储和网络文件系统预算**：
  - 预留约 3000−237.6−1036.8=1725.6 美元3000 - 237.6 - 1036.8 = 1725.6 \, \text{美元}3000−237.6−1036.8=1725.6美元 用于高性能存储和带宽扩展。

------

### **2. 高性能网络文件系统设计**

Azure提供了多种存储方案。根据无IB限制，选择以下文件系统进行挂载：

1. **选项：Azure NetApp Files（推荐）**

   - 优势：

     - 提供高IOPS和低延迟文件存储，适合并行计算和深度学习数据加载。
     - 简单挂载NFS，支持并行访问。

   - 成本估算：

     - 高性能NFS每TB约0.294美元/小时，假设挂载5TB： 72×5×0.294=105.84 美元72 \times 5 \times 0.294 = 105.84 \, \text{美元}72×5×0.294=105.84美元

2. **选项：BeeGFS（自部署方案）**
- 优势：

     - 简单易用，支持负载均衡，适合混合负载场景。
     - 支持并行访问，安装配置灵活。

   - 成本：

     - 主要为Azure SSD存储和CPU时间，假设用1TB高性能SSD： 72×1×0.122=8.78 美元72 \times 1 \times 0.122 = 8.78 \, \text{美元}72×1×0.122=8.78美元

3. **选项：Lustre on Azure**
- 优势：

     - 高性能，适合HPC场景。

   - 劣势：

     - 对IB优化，云上不一定具备最高性能。

**推荐**：

- **主文件系统**：Azure NetApp Files作为共享NFS主文件系统。
- **临时存储**：每个节点使用本地SSD作为Scratch存储，减轻NFS压力。

------

### **3. 基准测试计划**

#### **HPL和HPCG基准测试**

- **目标**：优化HB120rs_v3上的CPU性能。

- 优化方向：

  - HPL：

    - 优化参数 N,NB,P,QN, NB, P, QN,NB,P,Q，提升利用率。
    - 使用AMD Math Libraries (AOCL) 提供的线性代数库。

  - HPCG：

    - 调整线程数、OpenMP绑定策略。

#### **IO500基准测试**

- **目标**：评估文件系统IO性能，优化并发读写。

- 配置步骤：

  1. 下载并编译 IO500 测试程序。

  2. 配置文件`config.ini`：

     - **block_size**：根据NFS块大小调整。
     - **num_tasks**：根据总核数设置并发。

  3. 运行多轮测试，评估吞吐量和延迟。

------

### **4. 性能优化策略**

#### **任务分配**

- HB120rs_v3节点：

  - 主要运行CESM、HPL、HPCG任务，充分利用120核CPU性能。

- NC64as_T4_v3节点：

  - 主要运行Gromacs、AI训练（如PyTorch、TensorFlow）。
  - 确保CUDA环境和AI框架优化。

#### **负载优化**

1. **CESM**：
   - 使用MPI并行化模拟，划分子任务以提高效率。
   - 调整网格分辨率，适配节点内存容量。
2. **Gromacs**：
   - 启用GPU加速，确保最大化利用NVIDIA T4算力。
   - 调整PME（Particle Mesh Ewald）分解策略。
3. **AI LLM**：
   - 优化微批大小，平衡GPU显存和计算效率。
   - 使用混合精度训练，提升性能。

------

### **5. 集群搭建与操作流程**

1. **资源预订**：

   - 在Azure Portal中预留所需实例（HB120rs_v3和NC64as_T4_v3），配置共享存储。

2. **操作系统与驱动安装**：

   - 使用CentOS 7镜像。
   - 配置CUDA Toolkit、MPI、存储挂载。

3. **文件系统挂载**：

   - 挂载Azure NetApp Files NFS到所有节点：

     ```bash
     mount -t nfs <NFS_server>:/export /mnt/nfs
     ```
   
4. **基准测试部署**：

   - 下载并部署HPL、HPCG、IO500，完成优化和调试。

5. **科学计算任务运行**：

   - 使用任务调度工具（如Slurm或手动分配任务）运行科学计算负载。

------

### **6. 预算总结**

| 项目                   | 数量 | 单价（美元/小时） | 总计（美元） |
| ---------------------- | ---- | ----------------- | ------------ |
| **HB120rs_v3**         | 2台  | 1.65              | 237.6        |
| **NC64as_T4_v3**       | 4台  | 3.6               | 1036.8       |
| **Azure NetApp Files** | 5TB  | 0.294             | 105.84       |
| **总计**               |      |                   | **1380.24**  |

- 预留 **$3000 - $1380.24 = $1619.76** 作为应急和性能调优费用。

------

### **总结**

- **集群架构**：HB120rs_v3和NC64as_T4_v3的异构集群，挂载Azure NetApp Files作为主文件系统，辅以本地SSD。
- **任务分配**：CPU节点处理HPC任务，GPU节点负责AI和分子模拟。
- **测试与优化**：运行HPL、HPCG、IO500，通过多轮调优实现最优性能。
- **预算控制**：总预算约1380美元，充分满足性能和存储需求。





##### August说：

请给出类似的系统装配阶段的分工和流程。对比物理机的常规比赛，有哪些异同？哪些经验可以移植，而哪些知识技能需要重新学习？



###### ChatGPT 说：

ChatGPT

### **云上异构集群装配的分工与流程**

在Azure云环境中，异构集群的装配和调试流程与物理机有显著差异，但某些经验仍可复用。以下是云上系统装配的人员分工和具体流程，以及与物理机比赛的对比分析。

------

### **1. 云上装配的分工和流程**

#### **1.1 分工表**

| 角色               | 任务描述                                                     | 人员建议 |
| ------------------ | ------------------------------------------------------------ | -------- |
| **资源管理工程师** | 预定云资源（计算节点、存储服务等），配置云实例的网络拓扑，分配预算和监控费用。 | 1人      |
| **系统管理员**     | 安装操作系统（CentOS 7）及必要驱动（CUDA Toolkit、MPI等），完成文件系统挂载。 | 1-2人    |
| **网络管理员**     | 配置节点间通信网络，确保文件系统挂载正常，优化网络参数以适配高性能应用（如BeeGFS或NFS）。 | 1人      |
| **应用工程师**     | 部署科学计算应用（如CESM、Gromacs、AI训练框架），优化HPL、HPCG等基准测试性能。 | 2人      |
| **性能调优工程师** | 调整CPU、GPU利用率，优化MPI并行效率，完成IO500测试的多轮调试，最终获取最优性能。 | 1人      |
| **总协调人**       | 制定任务分配、监控进度，解决分工间问题，确保项目按计划完成。 | 1人      |

#### **1.2 装配流程**

1. **资源预定与预算管理**（2小时）：
   - 在Azure Portal中创建资源组，预定 **HB120rs_v3** 和 **NC64as_T4_v3** 节点。
   - 配置虚拟网络和存储服务（如Azure NetApp Files）。
   - 确保资源总成本符合预算限制。
2. **系统初始化与环境配置**（3小时）：
   - 为每个计算节点安装CentOS 7，确保一致性。
   - 部署CUDA驱动和MPI库，配置NFS或BeeGFS文件系统挂载。
3. **应用部署与验证**（3小时）：
   - 部署科学计算应用，并运行小规模测试。
   - 安装HPL、HPCG和IO500基准测试程序，检查依赖库是否完整。
4. **性能调优**（4小时）：
   - 运行多轮HPL和HPCG，调整参数 N,NB,P,QN, NB, P, QN,NB,P,Q 及线程绑定策略。
   - 调试IO500，优化文件系统并发和IO性能。
5. **任务调度与负载分配**（1小时）：
   - 编写任务调度脚本，分配科学计算负载到合适的节点。

------

### **2. 与物理机比赛的对比**

#### **2.1 异同点对比**

| **方面**           | **云上系统装配**                                             | **物理机系统装配**                                           |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **资源获取**       | 云资源按需预定，无需实际硬件搬运和安装，流程快速，但成本需实时监控。 | 需要现场安装服务器、交换机、GPU和存储设备，硬件搬运和调试复杂。 |
| **网络配置**       | 使用虚拟网络（VNet）连接节点，简单高效，但需要熟悉云服务提供商的配置界面和选项。 | 配置物理交换机和布线，需动手操作网络设备和调试低层网络连接。 |
| **存储系统**       | 高性能NFS、BeeGFS等挂载灵活，性能取决于云存储服务；无需部署物理存储设备。 | 部署Lustre、BeeGFS等文件系统需要搭建OSS/MDS节点，存储硬件和性能优化更复杂。 |
| **操作系统与驱动** | 云服务可提供预装操作系统镜像，部署快速；驱动兼容性和网络依赖更为简化。 | 需手动安装操作系统、硬件驱动及调整BIOS设置，对硬件驱动的支持要求高。 |
| **调试和测试**     | 虚拟化环境中无需硬件调试，但云上网络延迟、带宽性能可能受限。 | 需现场调试硬件故障、网络延迟和传输速率，优化工作量较大。     |
| **预算限制**       | 云平台费用需实时监控，资源利用率需高度优化以避免浪费。       | 硬件已购置，现场无需额外费用，但部署失误可能影响整体系统性能。 |
| **硬件管理**       | 云平台自动管理硬件故障，无需人工排查。                       | 需要熟悉硬件安装、监控和排障流程。                           |

#### **2.2 可移植的经验**

1. **性能调优经验**：
   - HPL和HPCG测试参数优化（如网格划分、线程绑定）在云上和物理机比赛均适用。
   - IO500测试的I/O优化策略（并发数、块大小调整）可直接移植。
2. **任务分配与管理**：
   - 任务调度策略（如按计算密集型任务分配至GPU节点，I/O密集型任务分配至高存储节点）在云上和物理机均适用。
3. **软件栈搭建**：
   - 熟悉MPI、CUDA Toolkit、科学计算库的部署和使用。

#### **2.3 云平台特有知识和技能**

1. **云服务接口与API**：
   - 熟悉Azure Portal界面及其CLI工具（如 `az` 命令行工具）。
   - 了解Azure资源管理的基础知识（如虚拟网络、存储挂载）。
2. **成本管理**：
   - 熟练使用Azure Cost Management工具，实时监控费用消耗，避免预算超支。
3. **虚拟网络配置**：
   - 配置VNet子网、负载均衡器和安全组，确保节点间通信和公网访问。
4. **高性能文件系统部署**：
   - 了解Azure NetApp Files、BeeGFS等云文件系统的特点和挂载方式。

------

### **3. 总结**

- **装配分工**：云平台简化了硬件安装和调试，但更依赖于对云服务配置的熟悉程度。
- **共通经验**：性能调优、科学计算负载管理、基准测试的优化策略是共通的。
- **云特有要求**：需要重新学习云服务的管理接口和API，尤其是网络、存储和成本管理。
- **关键建议**：提前熟悉Azure服务，尤其是资源分配和费用监控工具，确保在有限预算内完成最佳性能优化。